{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import collect_env, get_root_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  36,   37,   48, ...,   64,   64,    0],\n",
       "       [  39,   37,   39, ...,   64,   64,    0],\n",
       "       [  42,   40,   39, ...,   64,   64,    0],\n",
       "       ...,\n",
       "       [1526, 1389, 1418, ..., 1501, 1437,    0],\n",
       "       [1521, 1399, 1413, ..., 1491, 1433,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0]], dtype=uint16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path='/home/semyon/data/VinBigData/test/f6e32738dac91aec6faa814531dcb2d0.npy'\n",
    "mmcv.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mmcv.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config, DictAction\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('/home/semyon/projects/mmdetection/configs/vinbigdata/config.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.total_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.lr_config.warmup_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "output = subprocess.run([\"cat\", \"data.txt\"], capture_output=True)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/train.py /home/semyon/projects/mmdetection/configs/vinbigdata/config.py --cfg-options cfg.total_epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'checkpoint_config': {'interval': 1},\n",
      " 'classes': ('Aortic enlargement',\n",
      "             'Atelectasis',\n",
      "             'Calcification',\n",
      "             'Cardiomegaly',\n",
      "             'Consolidation',\n",
      "             'ILD',\n",
      "             'Infiltration',\n",
      "             'Lung Opacity',\n",
      "             'Nodule/Mass',\n",
      "             'Other lesion',\n",
      "             'Pleural effusion',\n",
      "             'Pleural thickening',\n",
      "             'Pneumothorax',\n",
      "             'Pulmonary fibrosis'),\n",
      " 'data': {'samples_per_gpu': 2,\n",
      "          'test': {'ann_file': 'data/coco/annotations/instances_val2017.json',\n",
      "                   'img_prefix': 'data/coco/val2017/',\n",
      "                   'pipeline': [{'type': 'LoadImageFromFile'},\n",
      "                                {'flip': False,\n",
      "                                 'img_scale': (1333, 800),\n",
      "                                 'transforms': [{'keep_ratio': True,\n",
      "                                                 'type': 'Resize'},\n",
      "                                                {'type': 'RandomFlip'},\n",
      "                                                {'mean': [123.675,\n",
      "                                                          116.28,\n",
      "                                                          103.53],\n",
      "                                                 'std': [58.395, 57.12, 57.375],\n",
      "                                                 'to_rgb': True,\n",
      "                                                 'type': 'Normalize'},\n",
      "                                                {'size_divisor': 32,\n",
      "                                                 'type': 'Pad'},\n",
      "                                                {'keys': ['img'],\n",
      "                                                 'type': 'ImageToTensor'},\n",
      "                                                {'keys': ['img'],\n",
      "                                                 'type': 'Collect'}],\n",
      "                                 'type': 'MultiScaleFlipAug'}],\n",
      "                   'type': 'CocoDataset'},\n",
      "          'train': {'ann_file': '/home/semyon/data/VinBigData/coco_formats/weighted_boxes_fusion_iou-0.20_fold-1234.json',\n",
      "                    'classes': ('Aortic enlargement',\n",
      "                                'Atelectasis',\n",
      "                                'Calcification',\n",
      "                                'Cardiomegaly',\n",
      "                                'Consolidation',\n",
      "                                'ILD',\n",
      "                                'Infiltration',\n",
      "                                'Lung Opacity',\n",
      "                                'Nodule/Mass',\n",
      "                                'Other lesion',\n",
      "                                'Pleural effusion',\n",
      "                                'Pleural thickening',\n",
      "                                'Pneumothorax',\n",
      "                                'Pulmonary fibrosis'),\n",
      "                    'img_prefix': '/home/semyon/data/VinBigData/train',\n",
      "                    'pipeline': [{'type': 'LoadImageFromFile'},\n",
      "                                 {'type': 'LoadAnnotations', 'with_bbox': True},\n",
      "                                 {'img_scale': (1333, 800),\n",
      "                                  'keep_ratio': True,\n",
      "                                  'type': 'Resize'},\n",
      "                                 {'flip_ratio': 0.5, 'type': 'RandomFlip'},\n",
      "                                 {'mean': [123.675, 116.28, 103.53],\n",
      "                                  'std': [58.395, 57.12, 57.375],\n",
      "                                  'to_rgb': True,\n",
      "                                  'type': 'Normalize'},\n",
      "                                 {'size_divisor': 32, 'type': 'Pad'},\n",
      "                                 {'type': 'DefaultFormatBundle'},\n",
      "                                 {'keys': ['img', 'gt_bboxes', 'gt_labels'],\n",
      "                                  'type': 'Collect'}],\n",
      "                    'type': 'CocoDataset'},\n",
      "          'val': {'ann_file': '/home/semyon/data/VinBigData/coco_formats/weighted_boxes_fusion_iou-0.20_fold-0.json',\n",
      "                  'classes': ('Aortic enlargement',\n",
      "                              'Atelectasis',\n",
      "                              'Calcification',\n",
      "                              'Cardiomegaly',\n",
      "                              'Consolidation',\n",
      "                              'ILD',\n",
      "                              'Infiltration',\n",
      "                              'Lung Opacity',\n",
      "                              'Nodule/Mass',\n",
      "                              'Other lesion',\n",
      "                              'Pleural effusion',\n",
      "                              'Pleural thickening',\n",
      "                              'Pneumothorax',\n",
      "                              'Pulmonary fibrosis'),\n",
      "                  'img_prefix': '/home/semyon/data/VinBigData/train',\n",
      "                  'pipeline': [{'type': 'LoadImageFromFile'},\n",
      "                               {'flip': False,\n",
      "                                'img_scale': (1333, 800),\n",
      "                                'transforms': [{'keep_ratio': True,\n",
      "                                                'type': 'Resize'},\n",
      "                                               {'type': 'RandomFlip'},\n",
      "                                               {'mean': [123.675,\n",
      "                                                         116.28,\n",
      "                                                         103.53],\n",
      "                                                'std': [58.395, 57.12, 57.375],\n",
      "                                                'to_rgb': True,\n",
      "                                                'type': 'Normalize'},\n",
      "                                               {'size_divisor': 32,\n",
      "                                                'type': 'Pad'},\n",
      "                                               {'keys': ['img'],\n",
      "                                                'type': 'ImageToTensor'},\n",
      "                                               {'keys': ['img'],\n",
      "                                                'type': 'Collect'}],\n",
      "                                'type': 'MultiScaleFlipAug'}],\n",
      "                  'type': 'CocoDataset'},\n",
      "          'workers_per_gpu': 2},\n",
      " 'data_root': 'data/coco/',\n",
      " 'dataset_type': 'COCODataset',\n",
      " 'dist_params': {'backend': 'nccl'},\n",
      " 'evaluation': {'interval': 1, 'metric': 'bbox'},\n",
      " 'img_norm_cfg': {'mean': [123.675, 116.28, 103.53],\n",
      "                  'std': [58.395, 57.12, 57.375],\n",
      "                  'to_rgb': True},\n",
      " 'load_from': None,\n",
      " 'log_config': {'hooks': [{'type': 'TextLoggerHook'}], 'interval': 50},\n",
      " 'log_level': 'INFO',\n",
      " 'lr_config': {'policy': 'step',\n",
      "               'step': [8, 11],\n",
      "               'warmup': 'linear',\n",
      "               'warmup_iters': 2000,\n",
      "               'warmup_ratio': 0.001},\n",
      " 'model': {'backbone': {'depth': 50,\n",
      "                        'frozen_stages': 1,\n",
      "                        'norm_cfg': {'requires_grad': True, 'type': 'BN'},\n",
      "                        'norm_eval': True,\n",
      "                        'num_stages': 4,\n",
      "                        'out_indices': (0, 1, 2, 3),\n",
      "                        'style': 'pytorch',\n",
      "                        'type': 'ResNet'},\n",
      "           'neck': {'in_channels': [256, 512, 1024, 2048],\n",
      "                    'num_outs': 5,\n",
      "                    'out_channels': 256,\n",
      "                    'type': 'FPN'},\n",
      "           'pretrained': 'torchvision://resnet50',\n",
      "           'roi_head': {'bbox_head': {'bbox_coder': {'target_means': [0.0,\n",
      "                                                                      0.0,\n",
      "                                                                      0.0,\n",
      "                                                                      0.0],\n",
      "                                                     'target_stds': [0.1,\n",
      "                                                                     0.1,\n",
      "                                                                     0.2,\n",
      "                                                                     0.2],\n",
      "                                                     'type': 'DeltaXYWHBBoxCoder'},\n",
      "                                      'fc_out_channels': 1024,\n",
      "                                      'in_channels': 256,\n",
      "                                      'loss_bbox': {'loss_weight': 1.0,\n",
      "                                                    'type': 'L1Loss'},\n",
      "                                      'loss_cls': {'loss_weight': 1.0,\n",
      "                                                   'type': 'CrossEntropyLoss',\n",
      "                                                   'use_sigmoid': False},\n",
      "                                      'num_classes': 14,\n",
      "                                      'reg_class_agnostic': False,\n",
      "                                      'roi_feat_size': 7,\n",
      "                                      'type': 'Shared2FCBBoxHead'},\n",
      "                        'bbox_roi_extractor': {'featmap_strides': [4,\n",
      "                                                                   8,\n",
      "                                                                   16,\n",
      "                                                                   32],\n",
      "                                               'out_channels': 256,\n",
      "                                               'roi_layer': {'output_size': 7,\n",
      "                                                             'sampling_ratio': 0,\n",
      "                                                             'type': 'RoIAlign'},\n",
      "                                               'type': 'SingleRoIExtractor'},\n",
      "                        'type': 'StandardRoIHead'},\n",
      "           'rpn_head': {'anchor_generator': {'ratios': [0.5, 1.0, 2.0],\n",
      "                                             'scales': [8],\n",
      "                                             'strides': [4, 8, 16, 32, 64],\n",
      "                                             'type': 'AnchorGenerator'},\n",
      "                        'bbox_coder': {'target_means': [0.0, 0.0, 0.0, 0.0],\n",
      "                                       'target_stds': [1.0, 1.0, 1.0, 1.0],\n",
      "                                       'type': 'DeltaXYWHBBoxCoder'},\n",
      "                        'feat_channels': 256,\n",
      "                        'in_channels': 256,\n",
      "                        'loss_bbox': {'loss_weight': 1.0, 'type': 'L1Loss'},\n",
      "                        'loss_cls': {'loss_weight': 1.0,\n",
      "                                     'type': 'CrossEntropyLoss',\n",
      "                                     'use_sigmoid': True},\n",
      "                        'type': 'RPNHead'},\n",
      "           'test_cfg': {'rcnn': {'max_per_img': 100,\n",
      "                                 'nms': {'iou_threshold': 0.5, 'type': 'nms'},\n",
      "                                 'score_thr': 0.05},\n",
      "                        'rpn': {'max_num': 1000,\n",
      "                                'min_bbox_size': 0,\n",
      "                                'nms_across_levels': False,\n",
      "                                'nms_post': 1000,\n",
      "                                'nms_pre': 1000,\n",
      "                                'nms_thr': 0.7}},\n",
      "           'train_cfg': {'rcnn': {'assigner': {'ignore_iof_thr': -1,\n",
      "                                               'match_low_quality': False,\n",
      "                                               'min_pos_iou': 0.5,\n",
      "                                               'neg_iou_thr': 0.5,\n",
      "                                               'pos_iou_thr': 0.5,\n",
      "                                               'type': 'MaxIoUAssigner'},\n",
      "                                  'debug': False,\n",
      "                                  'pos_weight': -1,\n",
      "                                  'sampler': {'add_gt_as_proposals': True,\n",
      "                                              'neg_pos_ub': -1,\n",
      "                                              'num': 512,\n",
      "                                              'pos_fraction': 0.25,\n",
      "                                              'type': 'RandomSampler'}},\n",
      "                         'rpn': {'allowed_border': -1,\n",
      "                                 'assigner': {'ignore_iof_thr': -1,\n",
      "                                              'match_low_quality': True,\n",
      "                                              'min_pos_iou': 0.3,\n",
      "                                              'neg_iou_thr': 0.3,\n",
      "                                              'pos_iou_thr': 0.7,\n",
      "                                              'type': 'MaxIoUAssigner'},\n",
      "                                 'debug': False,\n",
      "                                 'pos_weight': -1,\n",
      "                                 'sampler': {'add_gt_as_proposals': False,\n",
      "                                             'neg_pos_ub': -1,\n",
      "                                             'num': 256,\n",
      "                                             'pos_fraction': 0.5,\n",
      "                                             'type': 'RandomSampler'}},\n",
      "                         'rpn_proposal': {'max_num': 1000,\n",
      "                                          'min_bbox_size': 0,\n",
      "                                          'nms_across_levels': False,\n",
      "                                          'nms_post': 1000,\n",
      "                                          'nms_pre': 2000,\n",
      "                                          'nms_thr': 0.7}},\n",
      "           'type': 'FasterRCNN'},\n",
      " 'optimizer': {'lr': 0.001,\n",
      "               'momentum': 0.9,\n",
      "               'type': 'SGD',\n",
      "               'weight_decay': 0.0001},\n",
      " 'optimizer_config': {'grad_clip': None},\n",
      " 'resume_from': None,\n",
      " 'test_pipeline': [{'type': 'LoadImageFromFile'},\n",
      "                   {'flip': False,\n",
      "                    'img_scale': (1333, 800),\n",
      "                    'transforms': [{'keep_ratio': True, 'type': 'Resize'},\n",
      "                                   {'type': 'RandomFlip'},\n",
      "                                   {'mean': [123.675, 116.28, 103.53],\n",
      "                                    'std': [58.395, 57.12, 57.375],\n",
      "                                    'to_rgb': True,\n",
      "                                    'type': 'Normalize'},\n",
      "                                   {'size_divisor': 32, 'type': 'Pad'},\n",
      "                                   {'keys': ['img'], 'type': 'ImageToTensor'},\n",
      "                                   {'keys': ['img'], 'type': 'Collect'}],\n",
      "                    'type': 'MultiScaleFlipAug'}],\n",
      " 'total_epochs': 12,\n",
      " 'train_pipeline': [{'type': 'LoadImageFromFile'},\n",
      "                    {'type': 'LoadAnnotations', 'with_bbox': True},\n",
      "                    {'img_scale': (1333, 800),\n",
      "                     'keep_ratio': True,\n",
      "                     'type': 'Resize'},\n",
      "                    {'flip_ratio': 0.5, 'type': 'RandomFlip'},\n",
      "                    {'mean': [123.675, 116.28, 103.53],\n",
      "                     'std': [58.395, 57.12, 57.375],\n",
      "                     'to_rgb': True,\n",
      "                     'type': 'Normalize'},\n",
      "                    {'size_divisor': 32, 'type': 'Pad'},\n",
      "                    {'type': 'DefaultFormatBundle'},\n",
      "                    {'keys': ['img', 'gt_bboxes', 'gt_labels'],\n",
      "                     'type': 'Collect'}],\n",
      " 'workflow': [('train', 1)]}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (open-mmlab)",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
